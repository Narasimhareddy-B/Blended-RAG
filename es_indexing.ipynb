{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ef2788",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ES Indexing for Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ab6ccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "import requests\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b6546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ES_USER='elastic'\n",
    "ES_PASSWORD='78F4FX5Pn8Gnw3b779guSj2R'\n",
    "ES_URL='https://es-elastic.htalukder-sap-testing-2bef1f4b4097001da9502000c44fc2b2-0000.ca-tor.containers.appdomain.cloud/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1125bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.exceptions import RequestError\n",
    "# Create an instance of Elasticsearch with TLS options\n",
    "es_client = Elasticsearch(\n",
    "    ES_URL , \n",
    "    http_auth = (ES_USER, ES_PASSWORD),\n",
    "    verify = False\n",
    "    #ca_certs=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07bb329",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(\"https://elastic:78F4FX5Pn8Gnw3b779guSj2R@es-elastic.htalukder-sap-testing-2bef1f4b4097001da9502000c44fc2b2-0000.ca-tor.containers.appdomain.cloud\",\n",
    "                   ca_certs=False,\n",
    "                   verify_certs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2247e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "es.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800d36e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"research_index1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933693ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(index_name,mapping):\n",
    "    try:\n",
    "        es.indices.create(index=index_name,body = mapping)\n",
    "        print(f\"Index '{index_name}' created successfully.\")\n",
    "    except RequestError as e:\n",
    "        if e.error == 'resource_already_exists_exception':\n",
    "            print(f\"Index '{index_name}' already exists.\")\n",
    "        else:\n",
    "            print(f\"An error occurred while creating index '{index_name}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a988c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"id\": {\"type\": \"text\"},\n",
    "            \"source\": {\"type\": \"text\"},\n",
    "            \"title\": {\"type\": \"text\"},\n",
    "            \"text_field\": {\"type\": \"text\"},\n",
    "            \"metadata\": {\"type\": \"text\"}\n",
    "            \n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eeda71",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_index(index_name,index_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486b4384",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name_bm25 = 'research_index_bm25'\n",
    "index_mapping = {\n",
    "    \"settings\" :{\n",
    "    \"number_of_replicas\": 0,\n",
    "        \"number_of_shards\": 1,\n",
    "        \"refresh_interval\": \"1m\",\n",
    "        \"analysis\": {\n",
    "            \"filter\": {\n",
    "                \"possessive_english_stemmer\": {\n",
    "                    \"type\": \"stemmer\",\n",
    "                    \"language\": \"possessive_english\"\n",
    "                },\n",
    "                \"light_english_stemmer\": {\n",
    "                    \"type\": \"stemmer\",\n",
    "                    \"language\": \"light_english\"\n",
    "                },\n",
    "                \"english_stop\": {\n",
    "                    \"ignore_case\": \"true\",\n",
    "                    \"type\": \"stop\",\n",
    "                    \"stopwords\": [\"a\", \"about\", \"all\", \"also\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\",\n",
    "                                  \"be\", \"been\", \"but\", \"by\", \"can\", \"de\", \"did\", \"do\", \"does\", \"for\", \"from\",\n",
    "                                  \"had\", \"has\", \"have\", \"he\", \"her\", \"him\", \"his\", \"how\", \"if\", \"in\", \"into\",\n",
    "                                  \"is\", \"it\", \"its\", \"more\", \"my\", \"nbsp\", \"new\", \"no\", \"non\", \"not\", \"of\",\n",
    "                                  \"on\", \"one\", \"or\", \"other\", \"our\", \"she\", \"so\", \"some\", \"such\", \"than\",\n",
    "                                  \"that\", \"the\", \"their\", \"then\", \"there\", \"these\", \"they\", \"this\", \"those\",\n",
    "                                  \"thus\", \"to\", \"up\", \"us\", \"use\", \"was\", \"we\", \"were\", \"what\", \"when\", \"where\",\n",
    "                                  \"which\", \"while\", \"why\", \"will\", \"with\", \"would\", \"you\", \"your\", \"yours\"]\n",
    "                }\n",
    "            },\n",
    "            \"analyzer\": {\n",
    "                \"text_en_no_stop\": {\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\",\n",
    "                        \"possessive_english_stemmer\",\n",
    "                        \"light_english_stemmer\"\n",
    "                    ],\n",
    "                    \"tokenizer\": \"standard\"\n",
    "                },\n",
    "                \"text_en_stop\": {\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\",\n",
    "                        \"possessive_english_stemmer\",\n",
    "                        \"english_stop\",\n",
    "                        \"light_english_stemmer\"\n",
    "                    ],\n",
    "                    \"tokenizer\": \"standard\"\n",
    "                },\n",
    "                \"whitespace_lowercase\": {\n",
    "                    \"tokenizer\": \"whitespace\",\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\"\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            \"normalizer\": {\n",
    "                \"keyword_lowercase\": {\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"id\": {\"type\": \"text\"},\n",
    "            \"published_source\": {\"type\": \"text\"},\n",
    "            \"text\": \n",
    "            {\"type\": \"text\",\n",
    "             \"analyzer\": \"text_en_no_stop\",\n",
    "             \"search_analyzer\": \"text_en_stop\",\n",
    "             \"term_vector\": \"with_positions_offsets\",\n",
    "             \"index_options\": \"offsets\",\n",
    "             \"store\": \"true\"\n",
    "            },\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"metadata\": {\"type\": \"text\"},\n",
    "            \"source\": {\"type\": \"text\"}\n",
    "            \n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7886675",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name_bm25 = 'research_index_bm25'\n",
    "index_mapping = {\n",
    "    \"settings\" :{\n",
    "    \"number_of_replicas\": 0,\n",
    "        \"number_of_shards\": 1,\n",
    "        \"refresh_interval\": \"1m\",\n",
    "        \"analysis\": {\n",
    "            \"filter\": {\n",
    "                \"possessive_english_stemmer\": {\n",
    "                    \"type\": \"stemmer\",\n",
    "                    \"language\": \"possessive_english\"\n",
    "                },\n",
    "                \"light_english_stemmer\": {\n",
    "                    \"type\": \"stemmer\",\n",
    "                    \"language\": \"light_english\"\n",
    "                },\n",
    "                \"english_stop\": {\n",
    "                    \"ignore_case\": \"true\",\n",
    "                    \"type\": \"stop\",\n",
    "                    \"stopwords\": [\"a\", \"about\", \"all\", \"also\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\",\n",
    "                                  \"be\", \"been\", \"but\", \"by\", \"can\", \"de\", \"did\", \"do\", \"does\", \"for\", \"from\",\n",
    "                                  \"had\", \"has\", \"have\", \"he\", \"her\", \"him\", \"his\", \"how\", \"if\", \"in\", \"into\",\n",
    "                                  \"is\", \"it\", \"its\", \"more\", \"my\", \"nbsp\", \"new\", \"no\", \"non\", \"not\", \"of\",\n",
    "                                  \"on\", \"one\", \"or\", \"other\", \"our\", \"she\", \"so\", \"some\", \"such\", \"than\",\n",
    "                                  \"that\", \"the\", \"their\", \"then\", \"there\", \"these\", \"they\", \"this\", \"those\",\n",
    "                                  \"thus\", \"to\", \"up\", \"us\", \"use\", \"was\", \"we\", \"were\", \"what\", \"when\", \"where\",\n",
    "                                  \"which\", \"while\", \"why\", \"will\", \"with\", \"would\", \"you\", \"your\", \"yours\"]\n",
    "                }\n",
    "            },\n",
    "            \"analyzer\": {\n",
    "                \"text_en_no_stop\": {\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\",\n",
    "                        \"possessive_english_stemmer\",\n",
    "                        \"light_english_stemmer\"\n",
    "                    ],\n",
    "                    \"tokenizer\": \"standard\"\n",
    "                },\n",
    "                \"text_en_stop\": {\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\",\n",
    "                        \"possessive_english_stemmer\",\n",
    "                        \"english_stop\",\n",
    "                        \"light_english_stemmer\"\n",
    "                    ],\n",
    "                    \"tokenizer\": \"standard\"\n",
    "                },\n",
    "                \"whitespace_lowercase\": {\n",
    "                    \"tokenizer\": \"whitespace\",\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\"\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            \"normalizer\": {\n",
    "                \"keyword_lowercase\": {\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"id\": {\"type\": \"text\"},\n",
    "            \"published_source\": {\"type\": \"text\"},\n",
    "            \"text\": \n",
    "            {\"type\": \"text\",\n",
    "             \"analyzer\": \"text_en_no_stop\",\n",
    "             \"search_analyzer\": \"text_en_stop\",\n",
    "             \"term_vector\": \"with_positions_offsets\",\n",
    "             \"index_options\": \"offsets\",\n",
    "             \"store\": \"true\"\n",
    "            },\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"metadata\": {\"type\": \"text\"},\n",
    "            \"source\": {\"type\": \"text\"},\n",
    "            \"text.tokens\": { \n",
    "        \"type\": \"rank_features\" \n",
    "        }\n",
    "            \n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3acabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_index(index_name_bm25,index_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0e547f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name_knn = 'research_index_knn'\n",
    "index_mapping = {\n",
    "    \"settings\" :{\n",
    "    \"number_of_replicas\": 0,\n",
    "        \"number_of_shards\": 1,\n",
    "        \"refresh_interval\": \"1m\",\n",
    "        \"analysis\": {\n",
    "            \"filter\": {\n",
    "                \"possessive_english_stemmer\": {\n",
    "                    \"type\": \"stemmer\",\n",
    "                    \"language\": \"possessive_english\"\n",
    "                },\n",
    "                \"light_english_stemmer\": {\n",
    "                    \"type\": \"stemmer\",\n",
    "                    \"language\": \"light_english\"\n",
    "                },\n",
    "                \"english_stop\": {\n",
    "                    \"ignore_case\": \"true\",\n",
    "                    \"type\": \"stop\",\n",
    "                    \"stopwords\": [\"a\", \"about\", \"all\", \"also\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\",\n",
    "                                  \"be\", \"been\", \"but\", \"by\", \"can\", \"de\", \"did\", \"do\", \"does\", \"for\", \"from\",\n",
    "                                  \"had\", \"has\", \"have\", \"he\", \"her\", \"him\", \"his\", \"how\", \"if\", \"in\", \"into\",\n",
    "                                  \"is\", \"it\", \"its\", \"more\", \"my\", \"nbsp\", \"new\", \"no\", \"non\", \"not\", \"of\",\n",
    "                                  \"on\", \"one\", \"or\", \"other\", \"our\", \"she\", \"so\", \"some\", \"such\", \"than\",\n",
    "                                  \"that\", \"the\", \"their\", \"then\", \"there\", \"these\", \"they\", \"this\", \"those\",\n",
    "                                  \"thus\", \"to\", \"up\", \"us\", \"use\", \"was\", \"we\", \"were\", \"what\", \"when\", \"where\",\n",
    "                                  \"which\", \"while\", \"why\", \"will\", \"with\", \"would\", \"you\", \"your\", \"yours\"]\n",
    "                }\n",
    "            },\n",
    "            \"analyzer\": {\n",
    "                \"text_en_no_stop\": {\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\",\n",
    "                        \"possessive_english_stemmer\",\n",
    "                        \"light_english_stemmer\"\n",
    "                    ],\n",
    "                    \"tokenizer\": \"standard\"\n",
    "                },\n",
    "                \"text_en_stop\": {\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\",\n",
    "                        \"possessive_english_stemmer\",\n",
    "                        \"english_stop\",\n",
    "                        \"light_english_stemmer\"\n",
    "                    ],\n",
    "                    \"tokenizer\": \"standard\"\n",
    "                },\n",
    "                \"whitespace_lowercase\": {\n",
    "                    \"tokenizer\": \"whitespace\",\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\"\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            \"normalizer\": {\n",
    "                \"keyword_lowercase\": {\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"id\": {\"type\": \"text\"},\n",
    "            \"published_source\": {\"type\": \"text\"},\n",
    "            \"text\": \n",
    "            {\"type\": \"text\",\n",
    "             \"analyzer\": \"text_en_no_stop\",\n",
    "             \"search_analyzer\": \"text_en_stop\",\n",
    "             \"term_vector\": \"with_positions_offsets\",\n",
    "             \"index_options\": \"offsets\",\n",
    "             \"store\": \"true\"\n",
    "            },\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"metadata\": {\"type\": \"text\"},\n",
    "            \"source\": {\"type\": \"text\"},\n",
    "            \"text_embedding\": {\n",
    "                    \"type\": \"dense_vector\", \"dims\": 384,\n",
    "                    \"similarity\": \"cosine\", \"index\": \"true\"\n",
    "                }\n",
    "            \n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4245c916",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_index(index_name_knn,index_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc8e6c8",
   "metadata": {},
   "source": [
    "### 1. NQ_DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803a0677",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_folder = '/Users/abhilashamangal/Documents/Semantic Search/data/doc-nq910'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68914025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_files(folder_name):\n",
    "    # Change the directory\n",
    "    os.chdir(folder_name)\n",
    "    # iterate through all file\n",
    "    file_path_list =[]\n",
    "    for file in os.listdir():\n",
    "        print(file)\n",
    "        file_path = f\"{folder_name}/{file}\"\n",
    "        file_path_list.append(file_path)\n",
    "    return file_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25e8efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_all_files(doc_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89118b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docs = pd.read_csv(files[1],sep = '\\t') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba4ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4487f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cea476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0656211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nq_daatset(df_docs,source):\n",
    "    i=0\n",
    "    for index, row in df_docs.iterrows():\n",
    "        i=i+1\n",
    "        print(\"Processing i\",i)\n",
    "        id_ = row['id']\n",
    "        text = row['text']\n",
    "        title = row['title']\n",
    "        source = source\n",
    "        #text_embedding = model.encode(text)\n",
    "        doc ={\n",
    "                        \"id\": \"\"+title+\"\",\n",
    "                        \"source\": \"\"+source+\"\",\n",
    "                        \"text_field\": \"\"+text+\"\",\n",
    "                        \"title\": \"\"+title+\"\",\n",
    "                        \"metadata\": \"\"\n",
    "            }\n",
    "        doc_knn = {\n",
    "                        \"id\": \"\"+title+\"\",\n",
    "                        \"source\": \"\"+source+\"\",\n",
    "                        \"text\": \"\"+text+\"\",\n",
    "                        \"title\": \"\"+title+\"\",\n",
    "                        \"metadata\": \"\"\n",
    "                        #\"text_embedding\": text_embedding\n",
    "                    }\n",
    "        response = es.index(index=index_name, body=doc)\n",
    "        print(response)\n",
    "            #response = es.index(index=index_name_knn, body=doc_knn)\n",
    "            #print(response)           \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71df17ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nq_daatset_knn(df_docs,source):\n",
    "    i=0\n",
    "    for index, row in df_docs.iterrows():\n",
    "        i=i+1\n",
    "        print(\"Processing i\",i)\n",
    "        id_ = row['id']\n",
    "        text = row['text']\n",
    "        title = row['title']\n",
    "        source = source\n",
    "        text_embedding = model.encode(text)\n",
    "        doc_knn = {\n",
    "                        \"id\": \"\"+title+\"\",\n",
    "                        \"source\": \"\"+source+\"\",\n",
    "                        \"text\": \"\"+text+\"\",\n",
    "                        \"title\": \"\"+title+\"\",\n",
    "                        \"metadata\": \"\",\n",
    "                        \"text_embedding\": text_embedding\n",
    "                    }\n",
    "        response = es.index(index=index_name, body=doc_knn)\n",
    "        print(response)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f8fd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'nq_dataset'\n",
    "nq_daatset(df_docs,source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4deca8",
   "metadata": {},
   "source": [
    "2. LongNQ-doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cddfcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_folder_long = '/Users/abhilashamangal/Documents/Semantic Search/data/LongNQ-docs/'\n",
    "files_nq = get_all_files(doc_folder_long)\n",
    "df_docs_long = pd.read_csv(files_nq[1],sep = '\\t') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2576f54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_docs_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a58df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "source =\"longnq_doc\"\n",
    "nq_daatset(df_docs_long,source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ee29e5",
   "metadata": {},
   "source": [
    "3. Msmarco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c3f8678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qrels\n",
      ".DS_Store\n",
      "corpus.jsonl\n",
      "queries.jsonl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/abhilashamangal/Documents/Semantic Search/data/msmarco//corpus.jsonl'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_folder_msmarco = '/Users/abhilashamangal/Documents/Semantic Search/data/msmarco/'\n",
    "files_msmarco = get_all_files(doc_folder_msmarco)\n",
    "files_msmarco[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b802c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus = pd.read_json(files_msmarco[2],lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bea2de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92af8941",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d6b7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "source =\"msmarco\"\n",
    "nq_daatset(df_corpus,source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5b9910",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4. Trec-covid analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e43c9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_folder_trec = '/Users/abhilashamangal/Documents/Semantic Search/data/trec-covid/'\n",
    "files_trec = get_all_files(doc_folder_trec)\n",
    "df_corpus_trec = pd.read_json(files_trec[1],lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e39c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_corpus_trec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a486988f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus_trec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c6b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_data(df_docs,source):\n",
    "    i=0\n",
    "    for index, row in df_docs.iterrows():\n",
    "        if i > 152605:\n",
    "            print(\"Processing i\",i)\n",
    "            id_ = row['_id']\n",
    "            text = row['text']\n",
    "            title = row['title']\n",
    "            metadata = str(row['metadata'])\n",
    "            source = source\n",
    "            text_embedding = model.encode(text)\n",
    "            doc ={\n",
    "                    \"id\": \"\"+title+\"\",\n",
    "                    \"source\": \"\"+source+\"\",\n",
    "                    \"text\": \"\"+text+\"\",\n",
    "                    \"title\": \"\"+title+\"\",\n",
    "                    \"metadata\": \"\"+metadata+\"\",\n",
    "                }\n",
    "            doc_knn = {\n",
    "                    \"id\": \"\"+title+\"\",\n",
    "                    \"source\": \"\"+source+\"\",\n",
    "                    \"text\": \"\"+text+\"\",\n",
    "                    \"title\": \"\"+title+\"\",\n",
    "                    \"metadata\": \"\"+metadata+\"\",\n",
    "                    \"text_embedding\": text_embedding\n",
    "                }\n",
    "            response = es.index(index=index_name_bm25, body=doc)\n",
    "        #print(response)\n",
    "            response = es.index(index=index_name_knn, body=doc_knn)\n",
    "            print(response)\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b859e073",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_data(df_corpus_trec,\"trec\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
